{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Finding Donors for *CharityML*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data information\n",
    "We need to accurately model individuals' income using data collected from the 1994 U.S. Census.\n",
    "\n",
    "The dataset for this project originates from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Census+Income)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass education_level  education-num  marital-status  \\\n",
       "0   39   State-gov       Bachelors           13.0   Never-married   \n",
       "\n",
       "      occupation    relationship    race    sex  capital-gain  capital-loss  \\\n",
       "0   Adm-clerical   Not-in-family   White   Male        2174.0           0.0   \n",
       "\n",
       "   hours-per-week  native-country income  \n",
       "0            40.0   United-States  <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the Census dataset\n",
    "data = pd.read_csv(\"census.csv\")\n",
    "\n",
    "# Success - Display the first record\n",
    "display(data.head(n=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data Exploration\n",
    "\n",
    "- The total number of records\n",
    "- The number of individuals making more than \\$50,000 annually\n",
    "- The number of individuals making at most \\$50,000 annually\n",
    "- The percentage of individuals making more than \\$50,000 annually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 45222\n",
      "Individuals making more than $50,000: 11208\n",
      "Individuals making at most $50,000: 34014\n",
      "Percentage of individuals making more than $50,000: 24.78%\n"
     ]
    }
   ],
   "source": [
    "# Total number of records\n",
    "n_records = len(data)\n",
    "\n",
    "# Number of records where individual's income is more than $50,000\n",
    "n_greater_50k = len(data[data.income == '>50K'])\n",
    "\n",
    "# Number of records where individual's income is at most $50,000\n",
    "n_at_most_50k = len(data[data.income == '<=50K'])\n",
    "\n",
    "# Percentage of individuals whose income is more than $50,000\n",
    "greater_percent = (n_greater_50k/n_records)*100\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of records: {}\".format(n_records))\n",
    "print(\"Individuals making more than $50,000: {}\".format(n_greater_50k))\n",
    "print(\"Individuals making at most $50,000: {}\".format(n_at_most_50k))\n",
    "print(\"Percentage of individuals making more than $50,000: {:.2f}%\".format(greater_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Features **\n",
    "\n",
    "* **age**: continuous. \n",
    "* **workclass**: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. \n",
    "* **education**: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. \n",
    "* **education-num**: continuous. \n",
    "* **marital-status**: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. \n",
    "* **occupation**: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. \n",
    "* **relationship**: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. \n",
    "* **race**: Black, White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other. \n",
    "* **sex**: Female, Male. \n",
    "* **capital-gain**: continuous. \n",
    "* **capital-loss**: continuous. \n",
    "* **hours-per-week**: continuous. \n",
    "* **native-country**: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Preparing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target label\n",
    "income_raw = data['income']\n",
    "features_raw = data.drop('income', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform the skewed features\n",
    "skewed = ['capital-gain', 'capital-loss']\n",
    "features_log_transformed = pd.DataFrame(data = features_raw)\n",
    "features_log_transformed[skewed] = features_raw[skewed].apply(lambda x: np.log(x + 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.667492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age          workclass education_level  education-num  \\\n",
       "0  0.301370          State-gov       Bachelors       0.800000   \n",
       "1  0.452055   Self-emp-not-inc       Bachelors       0.800000   \n",
       "2  0.287671            Private         HS-grad       0.533333   \n",
       "3  0.493151            Private            11th       0.400000   \n",
       "4  0.150685            Private       Bachelors       0.800000   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0      0.667492           0.0        0.397959   United-States  \n",
       "1      0.000000           0.0        0.122449   United-States  \n",
       "2      0.000000           0.0        0.397959   United-States  \n",
       "3      0.000000           0.0        0.397959   United-States  \n",
       "4      0.000000           0.0        0.397959            Cuba  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import sklearn.preprocessing.StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "numerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\n",
    "features_log_minmax_transform[numerical] = scaler.fit_transform(features_log_transformed[numerical])\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "display(features_log_minmax_transform.head(n = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 total features after one-hot encoding.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing as pre\n",
    "\n",
    "# One-hot encode the 'features_log_minmax_transform' data using pandas.get_dummies()\n",
    "label = pre.LabelBinarizer()\n",
    "features_final = pd.get_dummies(features_log_minmax_transform)\n",
    "\n",
    "# Encode the 'income_raw' data to numerical values\n",
    "income = label.fit_transform(income_raw)\n",
    "\n",
    "# Print the number of features after one-hot encoding\n",
    "encoded = list(features_final.columns)\n",
    "print(\"{} total features after one-hot encoding.\".format(len(encoded)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 36177 samples.\n",
      "Testing set has 9045 samples.\n",
      "Training set has (36177, 1) smales.\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_final, \n",
    "                                                    income, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "print(\"Training set has {} smales.\".format(y_train.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Evaluating Model Performance\n",
    "In this section, we will investigate four different algorithms, and determine which is best at modeling the data. Three of these algorithms will be supervised learners of your choice, and the fourth algorithm is known as a *naive predictor*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import two metrics from sklearn - fbeta_score and accuracy_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    \n",
    "    results = {}\n",
    "  \n",
    "    y_train = np.ravel(y_train)\n",
    "    y_test = np.ravel(y_test)\n",
    "    \n",
    "    # Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:],training_labels[:])\n",
    "    start = time() # Get start time\n",
    "    learner = learner.fit(X_train[:sample_size],y_train[:sample_size])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the training time\n",
    "    results['train_time'] = (end-start)\n",
    "        \n",
    "    # Get the predictions on the test set(X_test),\n",
    "    #       then get predictions on the first 300 training samples(X_train) using .predict()\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the total prediction time\n",
    "    results['pred_time'] = (end-start)\n",
    "            \n",
    "    # Compute accuracy on the \n",
    "    \n",
    "    results['acc_train'] = accuracy_score(y_train[:300],predictions_train)\n",
    "        \n",
    "    # Compute accuracy on test set using accuracy_score()\n",
    "    results['acc_test'] = accuracy_score(y_test,predictions_test)\n",
    "    \n",
    "    # Compute F-score on the the first 300 training samples using fbeta_score()\n",
    "    results['f_train'] = fbeta_score(y_train[:300],predictions_train,beta=0.5)\n",
    "        \n",
    "    # Compute F-score on the test set which is y_test\n",
    "    results['f_test'] = fbeta_score(y_test,predictions_test,beta=0.5)\n",
    "       \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "        \n",
    "    # Return the results\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Initial Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "RandomForestClassifier trained on 361 samples.\n",
      "RandomForestClassifier trained on 3617 samples.\n",
      "RandomForestClassifier trained on 36177 samples.\n",
      "SGDClassifier\n",
      "SGDClassifier trained on 361 samples.\n",
      "SGDClassifier trained on 3617 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier trained on 36177 samples.\n",
      "SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC trained on 361 samples.\n",
      "SVC trained on 3617 samples.\n",
      "SVC trained on 36177 samples.\n"
     ]
    }
   ],
   "source": [
    "#Import the three supervised learning models from sklearn\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Initialize the three models\n",
    "clf_A = RandomForestClassifier(random_state = 0)\n",
    "clf_B = SGDClassifier(random_state = 47)\n",
    "clf_C = SVC(random_state = 49)\n",
    "\n",
    "# Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
    "# samples_100 is the entire training set i.e. len(y_train)\n",
    "# samples_10 is 10% of samples_100 (ensure to set the count of the values to be `int` and not `float`)\n",
    "# samples_1 is 1% of samples_100 (ensure to set the count of the values to be `int` and not `float`)\n",
    "samples_100 = len(y_train)\n",
    "samples_10 = int((1/10) * samples_100)\n",
    "samples_1 = int((1/100) * samples_100)\n",
    "\n",
    "# Collect results on the learners\n",
    "\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    print(clf_name)  \n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "Accuracy score on testing data: 0.8402\n",
      "F-score on testing data: 0.6780\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final accuracy score on the testing data: 0.8579\n",
      "Final F-score on the testing data: 0.7289\n",
      "Best parametets :{} {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 11}\n"
     ]
    }
   ],
   "source": [
    "#Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#Initialize the classifier\n",
    "clf =RandomForestClassifier(random_state = 47)\n",
    "\n",
    "# Create the parameters list you wish to tune, using a dictionary if needed.\n",
    "# parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}\n",
    "parameters = {'max_depth':[11,12,13,14,15],'min_samples_split':[9,10,11,12], 'min_samples_leaf':[1,2,3,4]}\n",
    "\n",
    "# Make an fbeta_score scoring object using make_scorer()\n",
    "scorer = make_scorer(fbeta_score,beta=0.5)\n",
    "\n",
    "# Perform grid search on the classifier using 'scorer' as the scoring method using GridSearchCV()\n",
    "grid_obj = GridSearchCV(clf,parameters,scoring=scorer)\n",
    "\n",
    "y_train = np.ravel(y_train)\n",
    "\n",
    "# Fit the grid search object to the training data and find the optimal parameters using fit()\n",
    "grid_fit = grid_obj.fit(X_train,y_train)\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n",
    "print(\"Best parametets :{}\",grid_fit.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Feature Importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf45af9898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import a supervised learning model that has 'feature_importances_'\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Train the supervised model on the training set using .fit(X_train, y_train)\n",
    "model = AdaBoostClassifier()\n",
    "y_train = np.ravel(y_train)\n",
    "boost_fit=model.fit(X_train,y_train)\n",
    "\n",
    "# Extract the feature importances using .feature_importances_ \n",
    "importances = boost_fit.feature_importances_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model trained on full data\n",
      "------\n",
      "Accuracy on testing data: 0.8579\n",
      "F-score on testing data: 0.7289\n",
      "\n",
      "Final Model trained on reduced data\n",
      "------\n",
      "Accuracy on testing data: 0.8334\n",
      "F-score on testing data: 0.6722\n"
     ]
    }
   ],
   "source": [
    "# Import functionality for cloning a model\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Reduce the feature space\n",
    "X_train_reduced = X_train[X_train.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "X_test_reduced = X_test[X_test.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "\n",
    "# Train on the \"best\" model found from grid search earlier\n",
    "clf = (clone(best_clf)).fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make new predictions\n",
    "reduced_predictions = clf.predict(X_test_reduced)\n",
    "\n",
    "# Report scores from the final model using both versions of data\n",
    "print(\"Final Model trained on full data\\n------\")\n",
    "print(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n",
    "print(\"\\nFinal Model trained on reduced data\\n------\")\n",
    "print(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, reduced_predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, reduced_predictions, beta = 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!!jupyter nbconvert *.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
